
import { GoogleGenAI } from "@google/genai";
import { AnalysisMetrics, YouTubeVideo } from "../types";

// ëª¨ë¸ ìš°ì„ ìˆœìœ„: gemini-3-flash-preview -> gemini-2.5-flash-latest -> gemini-flash-lite-latest
const MODELS = [
  'gemini-3-flash-preview',
  'gemini-2.5-flash-latest',
  'gemini-flash-lite-latest'
];

export const verifyGeminiApi = async (apiKey: string): Promise<boolean> => {
  if (!apiKey || !apiKey.trim()) return false;
  try {
    const ai = new GoogleGenAI({ apiKey: apiKey.trim() });
    // ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ ëª¨ë¸ë¡œ ë¨¼ì € í…ŒìŠ¤íŠ¸
    await ai.models.generateContent({
      model: MODELS[0],
      contents: 'ping',
      config: { maxOutputTokens: 1 }
    });
    return true;
  } catch (error) {
    console.error("Gemini Verification Error:", error);
    return false;
  }
};

export const analyzeWithGeminiStream = async (
  apiKey: string,
  keyword: string,
  metrics: AnalysisMetrics,
  onChunk: (text: string) => void
): Promise<void> => {
  if (!apiKey) return;
  const ai = new GoogleGenAI({ apiKey: apiKey.trim() });
  const prompt = `
      ë‹¹ì‹ ì€ ìœ íŠœë¸Œ ì•Œê³ ë¦¬ì¦˜ ë° ìˆ˜ìµí™” ì „ëµ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
      ë°ì´í„° ë¶„ì„ ê²°ê³¼: í‚¤ì›Œë“œ "${keyword}", ì‹œì¥ê·œëª¨ ${metrics.marketSizeLevel}, ë‚œì´ë„ ${metrics.difficultyLevel}.
      
      [ì‘ì„± ê°€ì´ë“œë¼ì¸]
      1. ğŸ” í‚¤ì›Œë“œ í™•ì¥ ë¶„ì„ (ì—°ê´€, ìœ ì‚¬, ë¡±í…Œì¼)
      2. ğŸ“Š ì½˜í…ì¸  í¬ë§· ë¶„ë¥˜ ë° ì˜ˆìƒ ë¹„ìœ¨ (%)
      3. ğŸ¯ ì‹œì¥ ì ì¬ë ¥ ë° ì•Œê³ ë¦¬ì¦˜ ë¶„ì„
      4. ğŸ’¡ ì°¨ë³„í™”ëœ ì½˜í…ì¸  ì£¼ì œ ì œì•ˆ
      5. ğŸ–¼ï¸ í´ë¦­ë¥  ê·¹ëŒ€í™” ì¸ë„¤ì¼ & ì¹´í”¼ ì „ëµ

      ì „ë¬¸ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ í†¤ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
    `;

  for (const modelName of MODELS) {
    try {
      const result = await ai.models.generateContentStream({
        model: modelName,
        contents: prompt,
      });

      for await (const chunk of result) {
        const text = chunk.text;
        if (text) onChunk(text);
      }
      return; // ì„±ê³µ ì‹œ í•¨ìˆ˜ ì¢…ë£Œ
    } catch (error: any) {
      const errorMessage = error?.message || "";
      // í• ë‹¹ëŸ‰ ì´ˆê³¼(429) ì—ëŸ¬ ë°œìƒ ì‹œ ë‹¤ìŒ ëª¨ë¸ë¡œ ì‹œë„
      if (MODELS.indexOf(modelName) < MODELS.length - 1 && 
          (errorMessage.includes("429") || errorMessage.includes("quota") || errorMessage.includes("exhausted") || errorMessage.includes("limit"))) {
        console.warn(`[Fallback] ${modelName} í• ë‹¹ëŸ‰ ì´ˆê³¼. ë‹¤ìŒ ëª¨ë¸ë¡œ ì‹œë„í•©ë‹ˆë‹¤.`);
        continue;
      }
      console.error(`Gemini Streaming Error (${modelName}):`, error);
      onChunk("\n\n[ì˜¤ë¥˜] ë¶„ì„ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. API í‚¤ì˜ í• ë‹¹ëŸ‰ì´ë‚˜ ê°€ìš© ì§€ì—­ì„ í™•ì¸í•´ì£¼ì„¸ìš”.");
      break;
    }
  }
};

export const generateVideoScript = async (apiKey: string, userPrompt: string): Promise<string> => {
  if (!apiKey) throw new Error("API Key missing");
  const ai = new GoogleGenAI({ apiKey: apiKey.trim() });
  const systemInstruction = `ë‹¹ì‹ ì€ 100ë§Œ ìœ íŠœë²„ ë©”ì¸ ì‘ê°€ì…ë‹ˆë‹¤. ê°•ë ¥í•œ í›„í‚¹ê³¼ ë¦¬í…ì…˜ ì„¤ê³„ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ëŒ€ë³¸ì„ ì‘ì„±í•˜ì„¸ìš”.`;

  for (const modelName of MODELS) {
    try {
      const response = await ai.models.generateContent({
        model: modelName,
        contents: userPrompt,
        config: { systemInstruction }
      });
      return response.text || "ëŒ€ë³¸ ìƒì„± ì‹¤íŒ¨";
    } catch (error: any) {
      const errorMessage = error?.message || "";
      if (MODELS.indexOf(modelName) < MODELS.length - 1 && 
          (errorMessage.includes("429") || errorMessage.includes("quota") || errorMessage.includes("exhausted") || errorMessage.includes("limit"))) {
        continue;
      }
      throw error;
    }
  }
  return "ëŒ€ë³¸ ìƒì„± ì‹¤íŒ¨";
};

export const generateVideoSpecificScript = async (apiKey: string, video: YouTubeVideo): Promise<string> => {
  if (!apiKey) throw new Error("API Key missing");
  const ai = new GoogleGenAI({ apiKey: apiKey.trim() });
  const prompt = `ì œëª©: ${video.snippet.title}\nì„¤ëª…: ${video.snippet.description}\nìœ„ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¦¬í…ì…˜ ìµœì í™” ëŒ€ë³¸ì„ ì¬êµ¬ì„±í•˜ì„¸ìš”.`;

  for (const modelName of MODELS) {
    try {
      const response = await ai.models.generateContent({
        model: modelName,
        contents: prompt,
      });
      return response.text || "ëŒ€ë³¸ ìƒì„± ì‹¤íŒ¨";
    } catch (error: any) {
      const errorMessage = error?.message || "";
      if (MODELS.indexOf(modelName) < MODELS.length - 1 && 
          (errorMessage.includes("429") || errorMessage.includes("quota") || errorMessage.includes("exhausted") || errorMessage.includes("limit"))) {
        continue;
      }
      throw error;
    }
  }
  return "ëŒ€ë³¸ ìƒì„± ì‹¤íŒ¨";
};
